{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMBFTztWlTVN/00OY1bKkJK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/oluwafemidiakhoa/AIGenesis_Engine/blob/main/Untitled429.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install adaptive-sparse-training\n"
      ],
      "metadata": {
        "id": "ZKyHAO_sIQsf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "inFWTUzbfdky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q adaptive-sparse-training gradio torchvision torch\n"
      ],
      "metadata": {
        "id": "s90PpP0zehci"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms, models\n",
        "from PIL import Image\n",
        "\n",
        "from adaptive_sparse_training import ASTConfig, AdaptiveSparseTrainer\n",
        "\n",
        "\n",
        "# 1. CIFAR-10 -> ImageFolder\n",
        "def prepare_cifar10_imagefolder(root: str = \"data/cifar10_imagefolder\") -> str:\n",
        "    root_path = Path(root)\n",
        "    train_root = root_path / \"train\"\n",
        "    val_root = root_path / \"val\"\n",
        "\n",
        "    if train_root.is_dir() and val_root.is_dir():\n",
        "        print(f\"[INFO] Using existing ImageFolder dataset at: {root_path}\")\n",
        "        return str(root_path)\n",
        "\n",
        "    print(f\"[INFO] Preparing CIFAR-10 at {root_path} ...\")\n",
        "    train_root.mkdir(parents=True, exist_ok=True)\n",
        "    val_root.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    cifar_train = datasets.CIFAR10(root=\"data\", train=True, download=True)\n",
        "    cifar_test = datasets.CIFAR10(root=\"data\", train=False, download=True)\n",
        "\n",
        "    classes = cifar_train.classes\n",
        "    print(\"[INFO] CIFAR-10 classes:\", classes)\n",
        "\n",
        "    to_pil = transforms.ToPILImage()\n",
        "\n",
        "    def dump_split(split_set, split_root: Path, split_name: str):\n",
        "        print(f\"[INFO] Saving {split_name} images to {split_root} ...\")\n",
        "        for idx, (img, label) in enumerate(split_set):\n",
        "            class_name = classes[label]\n",
        "            class_dir = split_root / class_name\n",
        "            class_dir.mkdir(parents=True, exist_ok=True)\n",
        "            img_pil: Image.Image = to_pil(img)\n",
        "            img_path = class_dir / f\"{idx:06d}.png\"\n",
        "            img_pil.save(img_path)\n",
        "        print(f\"[INFO] Finished saving {split_name}.\")\n",
        "\n",
        "    dump_split(cifar_train, train_root, \"train\")\n",
        "    dump_split(cifar_test, val_root, \"val\")\n",
        "\n",
        "    print(f\"[INFO] Done. ImageFolder dataset at: {root_path}\")\n",
        "    return str(root_path)\n",
        "\n",
        "\n",
        "# 2. Dataloaders\n",
        "def build_dataloaders(data_root: str, batch_size: int = 128, num_workers: int = 2):\n",
        "    train_dir = os.path.join(data_root, \"train\")\n",
        "    val_dir = os.path.join(data_root, \"val\")\n",
        "\n",
        "    assert os.path.isdir(train_dir), f\"Train directory not found: {train_dir}\"\n",
        "    assert os.path.isdir(val_dir), f\"Val directory not found: {val_dir}\"\n",
        "\n",
        "    train_tf = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "    ])\n",
        "\n",
        "    val_tf = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "    ])\n",
        "\n",
        "    train_ds = datasets.ImageFolder(train_dir, transform=train_tf)\n",
        "    val_ds = datasets.ImageFolder(val_dir, transform=val_tf)\n",
        "\n",
        "    classes = train_ds.classes\n",
        "    print(f\"[INFO] Classes ({len(classes)}): {classes}\")\n",
        "    print(f\"[INFO] Train samples: {len(train_ds)}, Val samples: {len(val_ds)}\")\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        train_ds,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=num_workers,\n",
        "        pin_memory=True,\n",
        "    )\n",
        "\n",
        "    val_loader = DataLoader(\n",
        "        val_ds,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=num_workers,\n",
        "        pin_memory=True,\n",
        "    )\n",
        "\n",
        "    return train_loader, val_loader, classes\n",
        "\n",
        "\n",
        "# 3. Model\n",
        "def build_model(num_classes: int, device: str = \"cuda\"):\n",
        "    try:\n",
        "        weights = models.ResNet18_Weights.DEFAULT\n",
        "        model = models.resnet18(weights=weights)\n",
        "    except AttributeError:\n",
        "        model = models.resnet18(weights=\"IMAGENET1K_V1\")\n",
        "    model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
        "    model = model.to(device)\n",
        "    return model\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(model: nn.Module, loader: DataLoader, device: str = \"cuda\") -> float:\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for inputs, targets in loader:\n",
        "        inputs = inputs.to(device)\n",
        "        targets = targets.to(device)\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "    return 100.0 * correct / total\n",
        "\n",
        "\n",
        "# 4. Train with AST + save model\n",
        "def main_train():\n",
        "    DATA_ROOT = \"data/cifar10_imagefolder\"\n",
        "    BATCH_SIZE = 128\n",
        "    NUM_WORKERS = 2\n",
        "\n",
        "    EPOCHS = 5\n",
        "    WARMUP_EPOCHS = 1\n",
        "    LEARNING_RATE = 3e-4\n",
        "    TARGET_ACTIVATION_RATE = 0.6\n",
        "\n",
        "    DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    print(f\"Using device: {DEVICE}\")\n",
        "\n",
        "    data_root = prepare_cifar10_imagefolder(DATA_ROOT)\n",
        "    train_loader, val_loader, classes = build_dataloaders(\n",
        "        data_root, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS\n",
        "    )\n",
        "\n",
        "    num_classes = len(classes)\n",
        "    model = build_model(num_classes, device=DEVICE)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss(reduction=\"none\")\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "    ast_config = ASTConfig(\n",
        "        target_activation_rate=TARGET_ACTIVATION_RATE,\n",
        "        adapt_kp=0.002,\n",
        "        adapt_ki=5e-5,\n",
        "        ema_alpha=0.2,\n",
        "        use_amp=True,\n",
        "        device=DEVICE,\n",
        "    )\n",
        "\n",
        "    trainer = AdaptiveSparseTrainer(\n",
        "        model=model,\n",
        "        train_loader=train_loader,\n",
        "        val_loader=val_loader,\n",
        "        config=ast_config,\n",
        "        optimizer=optimizer,\n",
        "        criterion=criterion,\n",
        "    )\n",
        "\n",
        "    print(\"Starting training...\")\n",
        "    print(f\"Starting training: {EPOCHS} epochs ({WARMUP_EPOCHS} warmup + {EPOCHS - WARMUP_EPOCHS} AST)\")\n",
        "    results = trainer.train(epochs=EPOCHS, warmup_epochs=WARMUP_EPOCHS)\n",
        "\n",
        "    final_val_acc = evaluate(model, val_loader, device=DEVICE)\n",
        "    energy_savings = None\n",
        "    if isinstance(results, dict):\n",
        "        energy_savings = results.get(\"energy_savings\", None)\n",
        "\n",
        "    print(\"\\n==================== SUMMARY ====================\")\n",
        "    print(f\"Final Validation Accuracy: {final_val_acc:.2f}%\")\n",
        "    if energy_savings is not None:\n",
        "        print(f\"Final Energy Savings: {energy_savings:.1f}%\")\n",
        "    else:\n",
        "        print(\"Final Energy Savings: (not returned in results dict)\")\n",
        "    print(\"=================================================\\n\")\n",
        "\n",
        "    # save model weights\n",
        "    torch.save(model.state_dict(), \"ast_cifar10_resnet18.pth\")\n",
        "    print(\"[INFO] Saved model to ast_cifar10_resnet18.pth\")\n",
        "    # save classes for later use\n",
        "    with open(\"cifar10_classes.txt\", \"w\") as f:\n",
        "        for c in classes:\n",
        "            f.write(c + \"\\n\")\n",
        "    print(\"[INFO] Saved class names to cifar10_classes.txt\")\n",
        "\n",
        "\n",
        "main_train()\n"
      ],
      "metadata": {
        "id": "VI6qso9qWM0u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "\n",
        "# Reuse build_model from above\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using device for Gradio:\", DEVICE)\n",
        "\n",
        "# Load classes\n",
        "with open(\"cifar10_classes.txt\") as f:\n",
        "    CLASSES = [line.strip() for line in f.readlines()]\n",
        "\n",
        "# Load model\n",
        "num_classes = len(CLASSES)\n",
        "model = build_model(num_classes, device=DEVICE)\n",
        "state_dict = torch.load(\"ast_cifar10_resnet18.pth\", map_location=DEVICE)\n",
        "model.load_state_dict(state_dict)\n",
        "model.eval()\n",
        "\n",
        "preprocess = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "def predict(image: Image.Image):\n",
        "    if image is None:\n",
        "        return {}\n",
        "    x = preprocess(image).unsqueeze(0).to(DEVICE)\n",
        "    with torch.no_grad():\n",
        "        logits = model(x)\n",
        "        probs = torch.softmax(logits, dim=1)[0]\n",
        "    return {CLASSES[i]: float(probs[i]) for i in range(len(CLASSES))}\n",
        "\n",
        "demo = gr.Interface(\n",
        "    fn=predict,\n",
        "    inputs=gr.Image(type=\"pil\", label=\"Upload CIFAR-like image\"),\n",
        "    outputs=gr.Label(num_top_classes=3, label=\"Top-3 Predictions\"),\n",
        "    title=\"AST CIFAR-10 Classifier\",\n",
        "    description=\"ResNet18 fine-tuned with Adaptive Sparse Training (AST) on CIFAR-10.\",\n",
        ")\n",
        "\n",
        "demo.launch(debug=True)\n"
      ],
      "metadata": {
        "id": "XEqhWB5fWVi6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import textwrap\n",
        "import os\n",
        "\n",
        "space_dir = \"space_app\"\n",
        "os.makedirs(space_dir, exist_ok=True)\n",
        "\n",
        "app_py = textwrap.dedent(\"\"\"\n",
        "    import torch\n",
        "    import torch.nn as nn\n",
        "    from torchvision import models, transforms\n",
        "    from torch.utils.data import DataLoader\n",
        "    from PIL import Image\n",
        "    import gradio as gr\n",
        "\n",
        "    DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "    # Load class names (make sure this file is in the Space)\n",
        "    with open(\"cifar10_classes.txt\") as f:\n",
        "        CLASSES = [line.strip() for line in f.readlines()]\n",
        "\n",
        "    def build_model(num_classes: int, device: str = \"cpu\"):\n",
        "        try:\n",
        "            weights = models.ResNet18_Weights.DEFAULT\n",
        "            model = models.resnet18(weights=weights)\n",
        "        except AttributeError:\n",
        "            model = models.resnet18(weights=\"IMAGENET1K_V1\")\n",
        "        model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
        "        model = model.to(device)\n",
        "        return model\n",
        "\n",
        "    num_classes = len(CLASSES)\n",
        "    model = build_model(num_classes, device=DEVICE)\n",
        "\n",
        "    state_dict = torch.load(\"ast_cifar10_resnet18.pth\", map_location=DEVICE)\n",
        "    model.load_state_dict(state_dict)\n",
        "    model.eval()\n",
        "\n",
        "    preprocess = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "    ])\n",
        "\n",
        "    def predict(image: Image.Image):\n",
        "        if image is None:\n",
        "            return {}\n",
        "        x = preprocess(image).unsqueeze(0).to(DEVICE)\n",
        "        with torch.no_grad():\n",
        "            logits = model(x)\n",
        "            probs = torch.softmax(logits, dim=1)[0]\n",
        "        return {CLASSES[i]: float(probs[i]) for i in range(len(CLASSES))}\n",
        "\n",
        "    demo = gr.Interface(\n",
        "        fn=predict,\n",
        "        inputs=gr.Image(type=\"pil\", label=\"Upload CIFAR-like image\"),\n",
        "        outputs=gr.Label(num_top_classes=3, label=\"Top-3 Predictions\"),\n",
        "        title=\"AST CIFAR-10 Classifier\",\n",
        "        description=\"ResNet18 fine-tuned with Adaptive Sparse Training (AST) on CIFAR-10.\",\n",
        "    )\n",
        "\n",
        "    if __name__ == \"__main__\":\n",
        "        demo.launch()Z\n",
        "\"\"\").strip() + \"\\n\"\n",
        "\n",
        "requirements_txt = textwrap.dedent(\"\"\"\n",
        "    gradio\n",
        "    torch\n",
        "    torchvision\n",
        "    pillow\n",
        "\"\"\").strip() + \"\\n\"\n",
        "\n",
        "with open(os.path.join(space_dir, \"app.py\"), \"w\") as f:\n",
        "    f.write(app_py)\n",
        "\n",
        "with open(os.path.join(space_dir, \"requirements.txt\"), \"w\") as f:\n",
        "    f.write(requirements_txt)\n",
        "\n",
        "print(\"[INFO] Created Hugging Face Space app files in 'space_app/'\")\n",
        "\n",
        "# Optional: zip it so you can download easily\n",
        "!zip -r space_app.zip space_app > /dev/null\n",
        "print(\"[INFO] Zipped to space_app.zip\")\n"
      ],
      "metadata": {
        "id": "gv9N9NBhgU7z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}